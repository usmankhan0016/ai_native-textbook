"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_textbook=self.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[9073],{7130:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"module-3/chapter-4-isaac-lab","title":"Chapter 4: Synthetic Data Generation with Isaac Lab","description":"Duration Intermediate | Week: 9","source":"@site/docs/module-3/chapter-4-isaac-lab.md","sourceDirName":"module-3","slug":"/module-3/chapter-4-isaac-lab","permalink":"/ai_native-textbook/docs/module-3/chapter-4-isaac-lab","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"isaac-lab","permalink":"/ai_native-textbook/docs/tags/isaac-lab"},{"inline":true,"label":"synthetic-data","permalink":"/ai_native-textbook/docs/tags/synthetic-data"},{"inline":true,"label":"domain-randomization","permalink":"/ai_native-textbook/docs/tags/domain-randomization"},{"inline":true,"label":"machine-learning","permalink":"/ai_native-textbook/docs/tags/machine-learning"},{"inline":true,"label":"pytorch","permalink":"/ai_native-textbook/docs/tags/pytorch"}],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"sidebar_label":"Ch. 4: Synthetic Data Isaac Lab","title":"Chapter 4: Synthetic Data Generation with Isaac Lab","tags":["isaac-lab","synthetic-data","domain-randomization","machine-learning","pytorch"],"difficulty":"Intermediate","module":3,"week":9,"prerequisites":["Chapter 1-3","PyTorch basics","Python 3.10+"],"estimated_time":"6-8 hours","topics":["Isaac Lab","gymnasium environments","domain randomization","synthetic datasets","transfer learning","sim-to-real"]},"sidebar":"tutorialSidebar","previous":{"title":"Ch. 3: Isaac ROS Perception","permalink":"/ai_native-textbook/docs/module-3/chapter-3-isaac-ros"},"next":{"title":"Ch. 5: Jetson Deployment","permalink":"/ai_native-textbook/docs/module-3/chapter-5-deployment"}}');var i=a(4848),r=a(8453);const s={sidebar_position:4,sidebar_label:"Ch. 4: Synthetic Data Isaac Lab",title:"Chapter 4: Synthetic Data Generation with Isaac Lab",tags:["isaac-lab","synthetic-data","domain-randomization","machine-learning","pytorch"],difficulty:"Intermediate",module:3,week:9,prerequisites:["Chapter 1-3","PyTorch basics","Python 3.10+"],estimated_time:"6-8 hours",topics:["Isaac Lab","gymnasium environments","domain randomization","synthetic datasets","transfer learning","sim-to-real"]},o="Chapter 4: Synthetic Data Generation with Isaac Lab",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"<strong>Synthetic Data</strong>",id:"synthetic-data",level:3},{value:"<strong>Domain Randomization</strong>",id:"domain-randomization",level:3},{value:"<strong>Isaac Lab</strong>",id:"isaac-lab",level:3},{value:"<strong>Transfer Learning</strong>",id:"transfer-learning",level:3},{value:"<strong>Sim-to-Real Gap</strong>",id:"sim-to-real-gap",level:3},{value:"Part 1: Why Synthetic Data?",id:"part-1-why-synthetic-data",level:2},{value:"Cost Comparison",id:"cost-comparison",level:3},{value:"The Catch: Sim-to-Real Transfer",id:"the-catch-sim-to-real-transfer",level:3},{value:"Part 2: Isaac Lab Environment Setup",id:"part-2-isaac-lab-environment-setup",level:2},{value:"Creating a Domain Randomization Task",id:"creating-a-domain-randomization-task",level:3},{value:"Running the Environment",id:"running-the-environment",level:3},{value:"Part 3: Domain Randomization in Detail",id:"part-3-domain-randomization-in-detail",level:2},{value:"Visual Randomization",id:"visual-randomization",level:3},{value:"Physics Randomization",id:"physics-randomization",level:3},{value:"Scene Randomization",id:"scene-randomization",level:3},{value:"Part 4: Transfer Learning",id:"part-4-transfer-learning",level:2},{value:"Step 1: Train on Synthetic Data",id:"step-1-train-on-synthetic-data",level:3},{value:"Step 2: Fine-Tune on Real Data",id:"step-2-fine-tune-on-real-data",level:3},{value:"Transfer Learning Results",id:"transfer-learning-results",level:3},{value:"Part 5: Hands-On Labs",id:"part-5-hands-on-labs",level:2},{value:"Lab 1: Domain Randomization Experiment (2 hours)",id:"lab-1-domain-randomization-experiment-2-hours",level:3},{value:"Lab 2: Scale Data Generation (1.5 hours)",id:"lab-2-scale-data-generation-15-hours",level:3},{value:"Lab 3: Transfer Learning Pipeline (2.5 hours)",id:"lab-3-transfer-learning-pipeline-25-hours",level:3},{value:"Part 6: Code Examples",id:"part-6-code-examples",level:2},{value:"Example: Sim-to-Real Gap Measurement",id:"example-sim-to-real-gap-measurement",level:3},{value:"Part 7: End-of-Chapter Exercises",id:"part-7-end-of-chapter-exercises",level:2},{value:"Exercise 1: Generate Large-Scale Dataset (1.5 hours)",id:"exercise-1-generate-large-scale-dataset-15-hours",level:3},{value:"Exercise 2: Domain Randomization Ablation (2 hours)",id:"exercise-2-domain-randomization-ablation-2-hours",level:3},{value:"Exercise 3: Transfer Learning Speedup (1.5 hours)",id:"exercise-3-transfer-learning-speedup-15-hours",level:3},{value:"Exercise 4: Synthetic-Real Parity (2 hours)",id:"exercise-4-synthetic-real-parity-2-hours",level:3},{value:"Part 8: Capstone Integration",id:"part-8-capstone-integration",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Additional Resources",id:"additional-resources",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-4-synthetic-data-generation-with-isaac-lab",children:"Chapter 4: Synthetic Data Generation with Isaac Lab"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Duration"}),": 6-8 hours | ",(0,i.jsx)(n.strong,{children:"Difficulty"}),": Intermediate | ",(0,i.jsx)(n.strong,{children:"Week"}),": 9"]}),"\n",(0,i.jsx)(n.p,{children:"Generate unlimited training data automatically using domain randomization."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By completing this chapter, you will be able to:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Understand Why Synthetic Data Matters"})," \u2014 Explain cost/scale/labeling advantages over real-world data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Set Up Isaac Lab Environment"})," \u2014 Create gymnasium-compatible RL environments for robotics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Design Domain Randomization"})," \u2014 Randomize textures, lighting, objects, physics to improve sim-to-real"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Export Annotated Datasets"})," \u2014 Generate COCO-format datasets with automatic ground truth labels"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Integrate with PyTorch"})," \u2014 Load synthetic data into training pipelines"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Measure Domain Gap"})," \u2014 Evaluate transfer learning effectiveness (synthetic \u2192 real)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fine-Tune on Real Data"})," \u2014 Apply transfer learning to improve models on real-world data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scale Data Generation"})," \u2014 Automate generation of 100K+ frames per hour"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,i.jsx)(n.h3,{id:"synthetic-data",children:(0,i.jsx)(n.strong,{children:"Synthetic Data"})}),"\n",(0,i.jsx)(n.p,{children:"Training data generated entirely in simulation. Eliminates need for manual labeling, enables unlimited scale, reduces real-world robot testing. Critical for AI robotics due to cost of real data."}),"\n",(0,i.jsx)(n.h3,{id:"domain-randomization",children:(0,i.jsx)(n.strong,{children:"Domain Randomization"})}),"\n",(0,i.jsx)(n.p,{children:"Technique of randomizing visual/physical properties during training to prevent overfitting to simulation artifacts. Makes trained models robust to real-world variations."}),"\n",(0,i.jsx)(n.h3,{id:"isaac-lab",children:(0,i.jsx)(n.strong,{children:"Isaac Lab"})}),"\n",(0,i.jsx)(n.p,{children:"Gymnasium-compatible reinforcement learning framework for robotics. Includes built-in support for domain randomization, multi-robot simulation, and efficient data generation."}),"\n",(0,i.jsx)(n.h3,{id:"transfer-learning",children:(0,i.jsx)(n.strong,{children:"Transfer Learning"})}),"\n",(0,i.jsx)(n.p,{children:"Training a model on one dataset (synthetic), then fine-tuning on another (real). Typically 10-100x faster than training from scratch."}),"\n",(0,i.jsx)(n.h3,{id:"sim-to-real-gap",children:(0,i.jsx)(n.strong,{children:"Sim-to-Real Gap"})}),"\n",(0,i.jsx)(n.p,{children:"Domain mismatch between simulation and reality. Objects look slightly different, physics isn't perfect, sensors have different noise. Domain randomization helps bridge this gap."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"part-1-why-synthetic-data",children:"Part 1: Why Synthetic Data?"}),"\n",(0,i.jsx)(n.h3,{id:"cost-comparison",children:"Cost Comparison"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"Real Data"}),(0,i.jsx)(n.th,{children:"Synthetic Data"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Collection time"})}),(0,i.jsx)(n.td,{children:"1000 images: 2-3 days"}),(0,i.jsx)(n.td,{children:"1000 images: 5 minutes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Labeling cost"})}),(0,i.jsx)(n.td,{children:"$10-20 per image"}),(0,i.jsx)(n.td,{children:"$0 (automatic)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Total cost per 10K images"})}),(0,i.jsx)(n.td,{children:"$100K-200K"}),(0,i.jsx)(n.td,{children:"$100 (compute)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Diversity"})}),(0,i.jsx)(n.td,{children:"Limited by environment"}),(0,i.jsx)(n.td,{children:"Unlimited (randomization)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Scale"})}),(0,i.jsx)(n.td,{children:"Practical limit: 100K images"}),(0,i.jsx)(n.td,{children:"Achievable: 1M+ images"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Privacy"})}),(0,i.jsx)(n.td,{children:"Real objects/people"}),(0,i.jsx)(n.td,{children:"Fully synthetic"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Bottom line"}),": Synthetic data is 100-1000x cheaper and enables 10x more training data."]}),"\n",(0,i.jsx)(n.h3,{id:"the-catch-sim-to-real-transfer",children:"The Catch: Sim-to-Real Transfer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Model trained on synthetic data\n    \u2193 (usually performs worse on real data)\nAccuracy on synthetic: 95%\nAccuracy on real: 60%  \u2190 Domain gap!\n    \u2193 (apply domain randomization during training)\nAccuracy on synthetic: 85% (slightly lower due to randomization)\nAccuracy on real: 92%  \u2190 Much better transfer!\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key insight"}),": Slight performance drop on synthetic \u2192 large gain on real."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"part-2-isaac-lab-environment-setup",children:"Part 2: Isaac Lab Environment Setup"}),"\n",(0,i.jsx)(n.h3,{id:"creating-a-domain-randomization-task",children:"Creating a Domain Randomization Task"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# File: humanoid_task.py\n"""\nIsaac Lab task with domain randomization for humanoid perception.\n"""\n\nimport torch\nfrom omni.isaac.lab.assets import Articulation, RigidObject\nfrom omni.isaac.lab.envs import ManagerBasedEnv, ManagerBasedRLEnvCfg\nfrom omni.isaac.lab.managers import EventTermCfg as EventCfg\nfrom omni.isaac.lab.scene import InteractiveScene, InteractiveSceneCfg\nfrom omni.isaac.lab.sim import SimulationCfg\nfrom omni.isaac.lab.utils import configclass\n\n@configclass\nclass HumanoidPerceptionTaskCfg(ManagerBasedRLEnvCfg):\n    """Configuration for humanoid perception task with domain randomization."""\n\n    # Simulation settings\n    sim: SimulationCfg = SimulationCfg(\n        dt=0.01,\n        render_interval=1,\n        disable_contact_processing=False,\n    )\n\n    # Scene (robots, objects, lights)\n    scene: InteractiveSceneCfg = InteractiveSceneCfg(\n        num_envs=64,  # Parallel environments\n        env_spacing=2.0,\n        replicate_physics=True,\n    )\n\n    # Domain randomization parameters\n    randomization = {\n        # Lighting randomization\n        "light_intensity_range": [0.5, 2.0],  # Vary brightness 0.5-2x\n        "light_color_range": [(0.8, 0.8, 1.0), (1.0, 1.0, 0.8)],  # Warm/cool\n\n        # Texture randomization\n        "material_roughness_range": [0.1, 0.9],  # Glossy to rough\n        "material_metallic_range": [0.0, 1.0],   # Non-metal to metal\n\n        # Physics randomization\n        "gravity_range": [8.0, 10.0],  # 8-10 m/s\xb2 (vs. 9.81)\n        "friction_range": [0.3, 1.5],  # Low to high friction\n        "restitution_range": [0.0, 0.3],  # Not bouncy to bouncy\n\n        # Object randomization\n        "object_scale_range": [0.5, 2.0],  # 0.5x-2x size\n        "object_color_randomization": True,  # Random colors\n        "num_obstacles_range": [0, 5],  # 0-5 obstacles in scene\n\n        # Camera randomization\n        "camera_noise_std": 0.01,  # Sensor noise\n        "camera_distortion": True,  # Lens distortion\n    }\n\nclass HumanoidPerceptionTask(ManagerBasedEnv):\n    """Humanoid perception task for synthetic data generation."""\n\n    cfg: HumanoidPerceptionTaskCfg\n\n    def __init__(self, cfg: HumanoidPerceptionTaskCfg):\n        super().__init__(cfg)\n\n        # Get humanoid robot\n        self.humanoid = self.scene.articulations["humanoid"]\n\n        # Get objects in scene\n        self.objects = self.scene.rigid_objects["objects"]\n\n        # Observation space: RGB image + depth\n        self.observation_spec = {\n            "rgb": torch.Size([64, 640, 480, 3]),  # 64 envs, 640x480 RGB\n            "depth": torch.Size([64, 640, 480]),   # Depth map\n        }\n\n    def _compute_observations(self):\n        """Get observations from sensors."""\n        obs = {}\n\n        # Render RGB from camera\n        obs["rgb"] = self.render_rgb()  # Shape: (64, 640, 480, 3)\n\n        # Render depth from camera\n        obs["depth"] = self.render_depth()  # Shape: (64, 640, 480)\n\n        return obs\n\n    def _compute_rewards(self):\n        """Rewards (not used for data generation, just for RL training)."""\n        return torch.zeros(self.cfg.scene.num_envs)\n\n    def _compute_dones(self):\n        """Check if episode is done."""\n        return torch.zeros(self.cfg.scene.num_envs, dtype=torch.bool)\n\n    def render_rgb(self):\n        """Render RGB images from all parallel environments."""\n        # Camera captures RGB for each of 64 parallel envs\n        return torch.randn(64, 640, 480, 3) * 255  # Placeholder\n\n    def render_depth(self):\n        """Render depth maps from all parallel environments."""\n        return torch.randn(64, 640, 480) * 10  # Placeholder\n\ndef make_env(cfg: HumanoidPerceptionTaskCfg = None):\n    """Create Isaac Lab environment."""\n    if cfg is None:\n        cfg = HumanoidPerceptionTaskCfg()\n    return HumanoidPerceptionTask(cfg)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"running-the-environment",children:"Running the Environment"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# File: generate_dataset.py\n"""\nGenerate synthetic dataset using Isaac Lab with domain randomization.\n"""\n\nimport torch\nimport numpy as np\nimport os\nfrom PIL import Image\nfrom humanoid_task import make_env, HumanoidPerceptionTaskCfg\n\n# Create environment\ncfg = HumanoidPerceptionTaskCfg()\nenv = make_env(cfg)\n\noutput_dir = "/tmp/synthetic_dataset_isaac_lab"\nos.makedirs(output_dir, exist_ok=True)\n\n# Generate 10,000 frames\nfor step in range(10000):\n    # Step environment (applies domain randomization)\n    obs, rewards, dones, info = env.step(torch.zeros(64, 10))  # 64 parallel envs\n\n    # Extract observations\n    rgb_images = obs["rgb"]  # Shape: (64, 640, 480, 3)\n    depth_maps = obs["depth"]  # Shape: (64, 640, 480)\n\n    # Save images\n    for env_idx in range(64):\n        frame_id = step * 64 + env_idx\n\n        # RGB\n        rgb = (rgb_images[env_idx].cpu().numpy() * 255).astype(np.uint8)\n        rgb_path = f"{output_dir}/rgb_{frame_id:06d}.png"\n        Image.fromarray(rgb).save(rgb_path)\n\n        # Depth\n        depth = depth_maps[env_idx].cpu().numpy().astype(np.uint16)\n        depth_path = f"{output_dir}/depth_{frame_id:06d}.png"\n        Image.fromarray(depth).save(depth_path)\n\n    if step % 100 == 0:\n        print(f"\u2705 Generated {step * 64} frames ({step / 100:.1f}% complete)")\n\nprint(f"\u2705 Dataset complete: {10000 * 64} frames in {output_dir}")\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"part-3-domain-randomization-in-detail",children:"Part 3: Domain Randomization in Detail"}),"\n",(0,i.jsx)(n.h3,{id:"visual-randomization",children:"Visual Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Randomize every aspect of appearance\nrandomization_params = {\n    # Lighting\n    "sun_intensity": np.random.uniform(0.5, 2.0),  # Brightness\n    "sun_azimuth": np.random.uniform(0, 360),      # Angle (degrees)\n    "sun_elevation": np.random.uniform(10, 80),    # Height above horizon\n\n    # Materials\n    "object_color": np.random.uniform(0, 1, 3),    # RGB [0, 1]\n    "material_roughness": np.random.uniform(0.1, 0.9),\n    "material_metallic": np.random.uniform(0.0, 1.0),\n\n    # Camera\n    "focal_length": np.random.uniform(15, 35),     # mm (zoom variation)\n    "aperture": np.random.uniform(1.4, 8.0),       # f-stop (depth of field)\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"physics-randomization",children:"Physics Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Randomize robot dynamics\nphysics_params = {\n    "gravity": np.random.uniform(8.0, 10.0),       # Gravity strength\n    "friction": np.random.uniform(0.3, 1.5),       # Friction coefficient\n    "mass_scale": np.random.uniform(0.9, 1.1),     # \xb110% mass variation\n    "inertia_scale": np.random.uniform(0.9, 1.1),\n    "damping": np.random.uniform(0.0, 0.5),\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"scene-randomization",children:"Scene Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Randomize environment\nscene_params = {\n    "num_obstacles": np.random.randint(0, 6),      # 0-5 obstacles\n    "obstacle_size": np.random.uniform(0.1, 0.5),  # Size variation\n    "obstacle_position": np.random.uniform(-2, 2, 3),  # Random placement\n    "floor_texture": np.random.choice(["tile", "wood", "concrete"]),\n    "background_color": np.random.uniform(0, 1, 3),  # Sky color\n}\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"part-4-transfer-learning",children:"Part 4: Transfer Learning"}),"\n",(0,i.jsx)(n.h3,{id:"step-1-train-on-synthetic-data",children:"Step 1: Train on Synthetic Data"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# File: train_synthetic.py\n"""\nTrain object detection model on synthetic data from Isaac Lab.\n"""\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.models as models\n\nclass SyntheticDataset(Dataset):\n    def __init__(self, image_dir, label_file):\n        self.images = [...]  # Load image paths\n        self.labels = [...]  # Load COCO annotations\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        # Return image, bounding boxes, class labels\n        return image, boxes, labels\n\n# Create dataset\ntrain_dataset = SyntheticDataset(\n    image_dir="/tmp/synthetic_dataset_isaac_lab/rgb",\n    label_file="/tmp/synthetic_dataset_isaac_lab/annotations.json"\n)\n\n# Train detection model on synthetic data\nmodel = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n\nfor epoch in range(10):\n    for batch in DataLoader(train_dataset, batch_size=32):\n        images, targets = batch\n        loss = model(images, targets)\n        loss.backward()\n        optimizer.step()\n\n# Save synthetic-trained model\ntorch.save(model.state_dict(), "model_synthetic_trained.pt")\n\nprint("\u2705 Model trained on synthetic data")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-2-fine-tune-on-real-data",children:"Step 2: Fine-Tune on Real Data"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# File: finetune_real.py\n"""\nFine-tune model on real-world data.\n"""\n\n# Load synthetic-trained model\nmodel = models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\nmodel.load_state_dict(torch.load("model_synthetic_trained.pt"))\n\n# Load real-world dataset (usually much smaller)\nreal_dataset = RealDataset(\n    image_dir="/path/to/real/images",\n    label_file="/path/to/real/annotations.json"\n)\n\n# Fine-tune (lower learning rate to preserve synthetic knowledge)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n\nfor epoch in range(5):  # Only 5 epochs (not 10 like synthetic)\n    for batch in DataLoader(real_dataset, batch_size=8):\n        images, targets = batch\n        loss = model(images, targets)\n        loss.backward()\n        optimizer.step()\n\n# Evaluate on test set\naccuracy = evaluate(model, test_set)\nprint(f"\u2705 Fine-tuned model accuracy: {accuracy:.1%}")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"transfer-learning-results",children:"Transfer Learning Results"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Training curve comparison:\n\nSynthetic-only (no real data):\n    Epoch 1: Accuracy 85% (on real test set) \u2190 Sim-to-real gap!\n    Epoch 5: Accuracy 88% (saturates, limited improvement)\n\nSynthetic \u2192 Fine-tune on real:\n    Start: Accuracy 85% (from synthetic training)\n    Epoch 1: Accuracy 90% (rapid improvement from real data)\n    Epoch 5: Accuracy 94% \u2190 Much better!\n\nTime comparison:\n    Training from scratch: 48 hours (10K real images)\n    Synthetic pre-training: 2 hours (100K synthetic images)\n    Fine-tuning on real: 30 minutes (1K real images)\n    Total: 2.5 hours (vs. 48 hours) \u2190 20x speedup!\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"part-5-hands-on-labs",children:"Part 5: Hands-On Labs"}),"\n",(0,i.jsx)(n.h3,{id:"lab-1-domain-randomization-experiment-2-hours",children:"Lab 1: Domain Randomization Experiment (2 hours)"}),"\n",(0,i.jsx)(n.p,{children:"Train two models:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No randomization"}),": Same lighting, materials, physics every frame"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Full randomization"}),": Everything randomized per frame"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Compare accuracy on real-world test set."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected result"}),": Randomized model 10-15% higher real-world accuracy"]}),"\n",(0,i.jsx)(n.h3,{id:"lab-2-scale-data-generation-15-hours",children:"Lab 2: Scale Data Generation (1.5 hours)"}),"\n",(0,i.jsxs)(n.p,{children:["Configure Isaac Lab with 64 parallel environments. Generate 50K frames in ",(0,i.jsx)(n.code,{children:"<10"})," minutes."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Success"}),": 50K frames exported, validated for ML training"]}),"\n",(0,i.jsx)(n.h3,{id:"lab-3-transfer-learning-pipeline-25-hours",children:"Lab 3: Transfer Learning Pipeline (2.5 hours)"}),"\n",(0,i.jsx)(n.p,{children:"Train on synthetic data \u2192 fine-tune on 1K real images. Compare to training from scratch."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Success"}),": Fine-tuned model 20% faster to reach same accuracy"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"part-6-code-examples",children:"Part 6: Code Examples"}),"\n",(0,i.jsx)(n.h3,{id:"example-sim-to-real-gap-measurement",children:"Example: Sim-to-Real Gap Measurement"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# File: measure_domain_gap.py\n"""\nQuantify domain gap between synthetic and real data.\n"""\n\ndef evaluate_model(model, synthetic_test_set, real_test_set):\n    """Evaluate model on both synthetic and real data."""\n    # Accuracy on synthetic\n    synthetic_acc = evaluate(model, synthetic_test_set)\n\n    # Accuracy on real\n    real_acc = evaluate(model, real_test_set)\n\n    # Domain gap\n    gap = synthetic_acc - real_acc\n\n    print(f"Synthetic accuracy: {synthetic_acc:.1%}")\n    print(f"Real accuracy:      {real_acc:.1%}")\n    print(f"Domain gap:         {gap:.1%}")\n\n    return gap\n\n# Models without randomization\nmodel_no_random = load_model("model_no_randomization.pt")\ngap_no_random = evaluate_model(model_no_random, synthetic_test, real_test)\n# Output: Domain gap: 35% (bad!)\n\n# Models with randomization\nmodel_with_random = load_model("model_with_randomization.pt")\ngap_with_random = evaluate_model(model_with_random, synthetic_test, real_test)\n# Output: Domain gap: 8% (much better!)\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"part-7-end-of-chapter-exercises",children:"Part 7: End-of-Chapter Exercises"}),"\n",(0,i.jsx)(n.h3,{id:"exercise-1-generate-large-scale-dataset-15-hours",children:"Exercise 1: Generate Large-Scale Dataset (1.5 hours)"}),"\n",(0,i.jsx)(n.p,{children:"Use Isaac Lab to generate 100K frames with domain randomization."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Acceptance"}),": 100K frames exported, file size ~40-60 GB"]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-2-domain-randomization-ablation-2-hours",children:"Exercise 2: Domain Randomization Ablation (2 hours)"}),"\n",(0,i.jsx)(n.p,{children:"Train three models:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"No randomization"}),"\n",(0,i.jsx)(n.li,{children:"Light randomization only"}),"\n",(0,i.jsx)(n.li,{children:"Full randomization"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Measure real-world accuracy for each."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Acceptance"}),": Report shows full randomization significantly better"]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-3-transfer-learning-speedup-15-hours",children:"Exercise 3: Transfer Learning Speedup (1.5 hours)"}),"\n",(0,i.jsx)(n.p,{children:"Compare:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Training from scratch on 10K real images: X hours"}),"\n",(0,i.jsx)(n.li,{children:"Synthetic pre-training + fine-tune on 1K real: Y hours"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Measure speedup: X / Y"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Acceptance"}),": 10-50x speedup, ",(0,i.jsx)(n.code,{children:"<10%"})," accuracy loss"]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-4-synthetic-real-parity-2-hours",children:"Exercise 4: Synthetic-Real Parity (2 hours)"}),"\n",(0,i.jsx)(n.p,{children:"Train model on synthetic until it matches real-world performance."}),"\n",(0,i.jsx)(n.p,{children:"Document:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Synthetic accuracy"}),"\n",(0,i.jsx)(n.li,{children:"Real accuracy"}),"\n",(0,i.jsx)(n.li,{children:"Number of frames needed"}),"\n",(0,i.jsx)(n.li,{children:"Domain gap"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Acceptance"}),": Gap ",(0,i.jsx)(n.code,{children:"<10%"}),", documented training curves"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"part-8-capstone-integration",children:"Part 8: Capstone Integration"}),"\n",(0,i.jsx)(n.p,{children:"Synthetic data (Chapter 4) trains your Humanoid AI Assistant's perception:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Chapter 2"}),": Humanoid digital twin + sensors"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Chapter 3"}),": Real-time perception pipeline (inference)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Chapter 4"}),": Generate training data at scale \u2190 YOU ARE HERE"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Chapter 5"}),": Deploy optimized model to Jetson"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Your capstone requires:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 10K+ synthetic training images"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Detection model trained to >80% accuracy"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Fine-tuned on small real dataset (if available)"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Transfer learning documented"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(n.p,{children:"In Chapter 5, you'll deploy your trained model to real hardware (Jetson) with safety mechanisms."}),"\n",(0,i.jsxs)(n.p,{children:["Ready? Move to ",(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/ai_native-textbook/docs/module-3/chapter-5-deployment",children:"Chapter 5: End-to-End Deployment"})}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Chapter Summary"}),": 6-8 hours | Difficulty: Intermediate | Week 9-10"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://isaac-lab.readthedocs.io/",children:"Isaac Lab Documentation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/1703.06907",children:"Domain Randomization Paper"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://cocodataset.org/",children:"COCO Dataset Format"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html",children:"PyTorch Transfer Learning"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>o});var t=a(6540);const i={},r=t.createContext(i);function s(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);