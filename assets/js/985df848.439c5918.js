"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_textbook=self.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[4117],{6496:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module-3/chapter-5-deployment","title":"Chapter 5: End-to-End Deployment: From Sim to Real Hardware","description":"Duration Intermediate | Week: 10","source":"@site/docs/module-3/chapter-5-deployment.md","sourceDirName":"module-3","slug":"/module-3/chapter-5-deployment","permalink":"/ai_native-textbook/docs/module-3/chapter-5-deployment","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"jetson","permalink":"/ai_native-textbook/docs/tags/jetson"},{"inline":true,"label":"deployment","permalink":"/ai_native-textbook/docs/tags/deployment"},{"inline":true,"label":"tensorrt","permalink":"/ai_native-textbook/docs/tags/tensorrt"},{"inline":true,"label":"optimization","permalink":"/ai_native-textbook/docs/tags/optimization"},{"inline":true,"label":"safety","permalink":"/ai_native-textbook/docs/tags/safety"},{"inline":true,"label":"production","permalink":"/ai_native-textbook/docs/tags/production"}],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"sidebar_label":"Ch. 5: Jetson Deployment","title":"Chapter 5: End-to-End Deployment: From Sim to Real Hardware","tags":["jetson","deployment","tensorrt","optimization","safety","production"],"difficulty":"Intermediate","module":3,"week":10,"prerequisites":["Chapter 1-4","ROS 2","Docker basics"],"estimated_time":"4-5 hours","topics":["Jetson hardware","model optimization","real-time control","safety mechanisms","deployment","production"]},"sidebar":"tutorialSidebar","previous":{"title":"Ch. 4: Synthetic Data Isaac Lab","permalink":"/ai_native-textbook/docs/module-3/chapter-4-isaac-lab"},"next":{"title":"Week 8: Isaac Foundations","permalink":"/ai_native-textbook/docs/module-3/week-8"}}');var r=t(4848),i=t(8453);const s={sidebar_position:5,sidebar_label:"Ch. 5: Jetson Deployment",title:"Chapter 5: End-to-End Deployment: From Sim to Real Hardware",tags:["jetson","deployment","tensorrt","optimization","safety","production"],difficulty:"Intermediate",module:3,week:10,prerequisites:["Chapter 1-4","ROS 2","Docker basics"],estimated_time:"4-5 hours",topics:["Jetson hardware","model optimization","real-time control","safety mechanisms","deployment","production"]},l="Chapter 5: End-to-End Deployment: From Sim to Real Hardware",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"<strong>Hardware Abstraction Layer (HAL)</strong>",id:"hardware-abstraction-layer-hal",level:3},{value:"<strong>Jetson</strong>",id:"jetson",level:3},{value:"<strong>Model Optimization</strong>",id:"model-optimization",level:3},{value:"<strong>Real-Time Latency Budget</strong>",id:"real-time-latency-budget",level:3},{value:"<strong>Safety Mechanisms</strong>",id:"safety-mechanisms",level:3},{value:"<strong>Graceful Degradation</strong>",id:"graceful-degradation",level:3},{value:"Part 1: Model Optimization for Jetson",id:"part-1-model-optimization-for-jetson",level:2},{value:"Converting PyTorch to TensorRT",id:"converting-pytorch-to-tensorrt",level:3},{value:"Quantization Strategy",id:"quantization-strategy",level:3},{value:"Part 2: Real-Time Control Loop",id:"part-2-real-time-control-loop",level:2},{value:"Latency Budget Allocation",id:"latency-budget-allocation",level:3},{value:"Part 3: Safety Mechanisms",id:"part-3-safety-mechanisms",level:2},{value:"Watchdog Timer",id:"watchdog-timer",level:3},{value:"Emergency Stop Implementation",id:"emergency-stop-implementation",level:3},{value:"Part 4: Deployment on Physical Jetson",id:"part-4-deployment-on-physical-jetson",level:2},{value:"Step 1: Prepare Jetson",id:"step-1-prepare-jetson",level:3},{value:"Step 2: Deploy Models",id:"step-2-deploy-models",level:3},{value:"Step 3: Run on Real Hardware",id:"step-3-run-on-real-hardware",level:3},{value:"Part 5: Hands-On Labs",id:"part-5-hands-on-labs",level:2},{value:"Lab 1: Model Optimization (1 hour)",id:"lab-1-model-optimization-1-hour",level:3},{value:"Lab 2: Real-Time Control Loop (1 hour)",id:"lab-2-real-time-control-loop-1-hour",level:3},{value:"Lab 3: Safety Mechanisms (1 hour)",id:"lab-3-safety-mechanisms-1-hour",level:3},{value:"Lab 4: Jetson Deployment (1 hour)",id:"lab-4-jetson-deployment-1-hour",level:3},{value:"Part 6: Troubleshooting Guide",id:"part-6-troubleshooting-guide",level:2},{value:"Issue: Model runs slow on Jetson",id:"issue-model-runs-slow-on-jetson",level:3},{value:"Issue: Latency spikes every few seconds",id:"issue-latency-spikes-every-few-seconds",level:3},{value:"Issue: Control loop misses deadline occasionally",id:"issue-control-loop-misses-deadline-occasionally",level:3},{value:"Part 7: End-of-Chapter Exercises",id:"part-7-end-of-chapter-exercises",level:2},{value:"Exercise 1: Optimize Your Model (1 hour)",id:"exercise-1-optimize-your-model-1-hour",level:3},{value:"Exercise 2: Deploy End-to-End (1.5 hours)",id:"exercise-2-deploy-end-to-end-15-hours",level:3},{value:"Exercise 3: Safety Testing (1 hour)",id:"exercise-3-safety-testing-1-hour",level:3},{value:"Exercise 4: Performance Documentation (1 hour)",id:"exercise-4-performance-documentation-1-hour",level:3},{value:"Part 8: Capstone Integration",id:"part-8-capstone-integration",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Optional: Chapter 6 (Advanced Topics)",id:"optional-chapter-6-advanced-topics",level:3},{value:"Continue to Module 4",id:"continue-to-module-4",level:3},{value:"Additional Resources",id:"additional-resources",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"chapter-5-end-to-end-deployment-from-sim-to-real-hardware",children:"Chapter 5: End-to-End Deployment: From Sim to Real Hardware"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Duration"}),": 4-5 hours | ",(0,r.jsx)(n.strong,{children:"Difficulty"}),": Intermediate | ",(0,r.jsx)(n.strong,{children:"Week"}),": 10"]}),"\n",(0,r.jsx)(n.p,{children:"Deploy your trained AI models to real hardware with safety guarantees."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By completing this chapter, you will be able to:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Design Hardware Abstraction Layers"})," \u2014 Write code that runs identically in simulation and on real hardware"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimize Models for Jetson"})," \u2014 Convert PyTorch models to TensorRT with quantization for 10x speedup"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implement Real-Time Control"})," \u2014 Design latency-critical perception-control loops"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Deploy Safety Mechanisms"})," \u2014 Add watchdogs, emergency stops, graceful failure handling"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Measure Performance"})," \u2014 Profile deployment on physical hardware"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Debug Hardware Issues"})," \u2014 Troubleshoot common deployment problems"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Document Procedures"})," \u2014 Write clear deployment guides for production"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Handle Hardware Failures"})," \u2014 Implement robust error recovery"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,r.jsx)(n.h3,{id:"hardware-abstraction-layer-hal",children:(0,r.jsx)(n.strong,{children:"Hardware Abstraction Layer (HAL)"})}),"\n",(0,r.jsx)(n.p,{children:"Software interface that isolates robot control code from hardware differences. Same ROS 2 code runs in Isaac Sim and on physical Jetson."}),"\n",(0,r.jsx)(n.h3,{id:"jetson",children:(0,r.jsx)(n.strong,{children:"Jetson"})}),"\n",(0,r.jsx)(n.p,{children:"NVIDIA's edge AI processor. Models Orin Nano (8GB, $200), Orin AGX (64GB, $2000), Xavier (8GB, ~$300). Combines CPU + GPU + AI accelerators (VIC, DLA)."}),"\n",(0,r.jsx)(n.h3,{id:"model-optimization",children:(0,r.jsx)(n.strong,{children:"Model Optimization"})}),"\n",(0,r.jsx)(n.p,{children:"Reducing model size/latency without significant accuracy loss. TensorRT enables: quantization (FP32\u2192INT8), operator fusion, memory optimization."}),"\n",(0,r.jsx)(n.h3,{id:"real-time-latency-budget",children:(0,r.jsx)(n.strong,{children:"Real-Time Latency Budget"})}),"\n",(0,r.jsx)(n.p,{children:"Allocation of time across perception \u2192 inference \u2192 control. Example: 100 ms total = 30 ms perception + 50 ms inference + 20 ms control."}),"\n",(0,r.jsx)(n.h3,{id:"safety-mechanisms",children:(0,r.jsx)(n.strong,{children:"Safety Mechanisms"})}),"\n",(0,r.jsx)(n.p,{children:"Watchdog timers, emergency stops, heartbeat monitoring. Ensure robot fails safely if any component freezes."}),"\n",(0,r.jsx)(n.h3,{id:"graceful-degradation",children:(0,r.jsx)(n.strong,{children:"Graceful Degradation"})}),"\n",(0,r.jsx)(n.p,{children:"Operating with reduced capability when systems fail. Example: If vision fails, use LiDAR as fallback."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-1-model-optimization-for-jetson",children:"Part 1: Model Optimization for Jetson"}),"\n",(0,r.jsx)(n.h3,{id:"converting-pytorch-to-tensorrt",children:"Converting PyTorch to TensorRT"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# File: optimize_model.py\n"""\nConvert trained object detection model to TensorRT for Jetson deployment.\n"""\n\nimport torch\nimport tensorrt as trt\nfrom torch2trt import torch2trt, TRTModule\n\ndef load_trained_model():\n    """Load PyTorch model trained in Chapter 4."""\n    import torchvision.models as models\n    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=91)\n    model.load_state_dict(torch.load("model_synthetic_trained.pt"))\n    model.eval()\n    model.cuda()\n    return model\n\ndef convert_to_tensorrt(model, input_shape=(1, 3, 640, 480)):\n    """Convert PyTorch model to TensorRT engine."""\n    print(f"Converting model to TensorRT...")\n\n    # Create dummy input matching expected shape\n    example_input = torch.randn(input_shape).cuda()\n\n    # Convert PyTorch \u2192 TensorRT\n    # Enables: FP16 inference, operator fusion, memory optimization\n    model_trt = torch2trt(\n        model,\n        [example_input],\n        fp16_mode=True,  # 16-bit floating point (2x speedup, minimal accuracy loss)\n        max_workspace_size=1 << 32,  # 4 GB workspace for optimization\n    )\n\n    return model_trt\n\ndef quantize_to_int8(model_trt):\n    """Further quantize to INT8 for extreme speed (optional)."""\n    # INT8 quantization: 32-bit \u2192 8-bit integers\n    # Trade-off: 8x speedup vs. accuracy loss\n    print("Note: INT8 quantization requires calibration dataset")\n    print("This step is optional - FP16 usually sufficient for real-time")\n    # For production use, provide calibration images\n\ndef benchmark_model(model_trt, warmup_runs=10, benchmark_runs=100):\n    """Benchmark model speed on Jetson."""\n    dummy_input = torch.randn(1, 3, 640, 480).cuda()\n\n    # Warmup\n    for _ in range(warmup_runs):\n        with torch.no_grad():\n            _ = model_trt(dummy_input)\n\n    # Benchmark\n    torch.cuda.synchronize()\n    t_start = time.perf_counter()\n\n    for _ in range(benchmark_runs):\n        with torch.no_grad():\n            _ = model_trt(dummy_input)\n\n    torch.cuda.synchronize()\n    t_end = time.perf_counter()\n\n    latency_ms = (t_end - t_start) / benchmark_runs * 1000\n    fps = 1000 / latency_ms\n\n    print(f"\\n=== Jetson Inference Benchmark ===")\n    print(f"Latency:  {latency_ms:.2f} ms")\n    print(f"FPS:      {fps:.1f}")\n    print(f"Budget:   30 ms (for 33 FPS target)")\n    if latency_ms < 30:\n        print("\u2705 Meets real-time requirement")\n    else:\n        print("\u26a0\ufe0f  Exceeds real-time budget - consider INT8 quantization")\n\nif __name__ == "__main__":\n    import time\n\n    # Load trained model from Chapter 4\n    model = load_trained_model()\n    print(f"Loaded PyTorch model")\n    print(f"  Original size: ~200 MB (FP32)")\n\n    # Convert to TensorRT FP16\n    model_trt = convert_to_tensorrt(model)\n    print(f"Converted to TensorRT FP16")\n    print(f"  Optimized size: ~100 MB (50% reduction)")\n\n    # Benchmark on Jetson\n    benchmark_model(model_trt)\n\n    # Save optimized model for deployment\n    torch.jit.save(model_trt, "model_jetson_optimized.pt")\n    print(f"\\n\u2705 Saved optimized model: model_jetson_optimized.pt")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"quantization-strategy",children:"Quantization Strategy"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Precision"}),(0,r.jsx)(n.th,{children:"Size"}),(0,r.jsx)(n.th,{children:"Latency"}),(0,r.jsx)(n.th,{children:"Accuracy"}),(0,r.jsx)(n.th,{children:"Use Case"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"FP32"})}),(0,r.jsx)(n.td,{children:"200 MB"}),(0,r.jsx)(n.td,{children:"120 ms"}),(0,r.jsx)(n.td,{children:"100%"}),(0,r.jsx)(n.td,{children:"Development/cloud"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"FP16"})}),(0,r.jsx)(n.td,{children:"100 MB"}),(0,r.jsx)(n.td,{children:"40 ms"}),(0,r.jsx)(n.td,{children:"99.5%"}),(0,r.jsx)(n.td,{children:"Jetson AGX (fast GPU)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"INT8"})}),(0,r.jsx)(n.td,{children:"50 MB"}),(0,r.jsx)(n.td,{children:"15 ms"}),(0,r.jsx)(n.td,{children:"95%"}),(0,r.jsx)(n.td,{children:"Jetson Nano (limited compute)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Binary"})}),(0,r.jsx)(n.td,{children:"25 MB"}),(0,r.jsx)(n.td,{children:"8 ms"}),(0,r.jsx)(n.td,{children:"85%"}),(0,r.jsx)(n.td,{children:"Extreme edge (research)"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-2-real-time-control-loop",children:"Part 2: Real-Time Control Loop"}),"\n",(0,r.jsx)(n.h3,{id:"latency-budget-allocation",children:"Latency Budget Allocation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# File: realtime_control_loop.py\n"""\nReal-time control loop with latency budgeting.\n"""\n\nimport time\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom geometry_msgs.msg import Twist\nimport numpy as np\n\nclass RealtimeControlNode(Node):\n    """Control loop running at fixed rate with latency monitoring."""\n\n    def __init__(self):\n        super().__init__(\'realtime_control\')\n\n        # Latency budget (ms)\n        self.budget = {\n            \'perception\': 20,      # Image processing + inference\n            \'control_logic\': 5,    # Decision making\n            \'command_publish\': 5,  # Send command to robot\n            \'buffer\': 3,           # Safety margin\n            \'total\': 33,           # 30 FPS = 33.3 ms per frame\n        }\n\n        self.latencies = {}\n\n        # Subscribe/publish\n        self.image_sub = self.create_subscription(\n            Image, \'/camera/image_raw\', self.image_callback, 10)\n        self.cmd_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n\n        # Timer at fixed rate (30 Hz)\n        self.timer = self.create_timer(0.033, self.control_loop)  # 30 Hz\n        self.loop_count = 0\n\n    def image_callback(self, msg: Image):\n        """Called when image arrives (async)."""\n        self.latest_image = msg\n\n    def control_loop(self):\n        """Main control loop at 30 Hz."""\n        self.loop_count += 1\n        loop_start = time.perf_counter()\n\n        # ==================== PERCEPTION ====================\n        percept_start = time.perf_counter()\n\n        # 1. Get image\n        if not hasattr(self, \'latest_image\'):\n            return\n\n        # 2. Run inference (TensorRT optimized)\n        detections = self.run_inference(self.latest_image)\n\n        percept_time = (time.perf_counter() - percept_start) * 1000\n        self.latencies[\'perception\'] = percept_time\n\n        # Check budget\n        if percept_time > self.budget[\'perception\']:\n            self.get_logger().warn(\n                f"Perception slow: {percept_time:.1f}ms (budget: {self.budget[\'perception\']}ms)")\n\n        # ==================== CONTROL LOGIC ====================\n        control_start = time.perf_counter()\n\n        # 3. Make decision based on detections\n        target_velocity = self.decide_action(detections)\n\n        control_time = (time.perf_counter() - control_start) * 1000\n        self.latencies[\'control\'] = control_time\n\n        # ==================== COMMAND PUBLISH ====================\n        pub_start = time.perf_counter()\n\n        # 4. Publish command\n        cmd_msg = Twist()\n        cmd_msg.linear.x = target_velocity[0]\n        cmd_msg.angular.z = target_velocity[1]\n        self.cmd_pub.publish(cmd_msg)\n\n        pub_time = (time.perf_counter() - pub_start) * 1000\n        self.latencies[\'publish\'] = pub_time\n\n        # ==================== MONITORING ====================\n        total_time = (time.perf_counter() - loop_start) * 1000\n\n        # Monitor latency\n        if self.loop_count % 30 == 0:  # Every 1 second\n            self.report_latency(total_time)\n\n    def run_inference(self, image_msg):\n        """Run TensorRT inference on image."""\n        # Convert ROS message to tensor\n        image_array = np.frombuffer(image_msg.data, dtype=np.uint8).reshape(\n            image_msg.height, image_msg.width, 3)\n\n        # Run inference (very fast on Jetson with TensorRT)\n        with torch.no_grad():\n            output = self.model_trt(torch.tensor(image_array).cuda())\n\n        return output\n\n    def decide_action(self, detections):\n        """Simple control logic: move toward detected object."""\n        if len(detections) == 0:\n            return [0.0, 0.0]  # Stop\n\n        # Move toward center of detections\n        center_x = np.mean([d[0] for d in detections])\n        center_y = np.mean([d[1] for d in detections])\n\n        # Simple proportional control\n        v_linear = 0.5 if len(detections) > 0 else 0.0\n        v_angular = (center_x - 320) / 320 * 0.5  # Turn toward object\n\n        return [v_linear, v_angular]\n\n    def report_latency(self, total_time):\n        """Report latency metrics."""\n        print(f"\\n=== Latency Report (Loop {self.loop_count}) ===")\n        for component, latency in self.latencies.items():\n            budget = self.budget.get(component, 10)\n            status = "\u2705" if latency < budget else "\u26a0\ufe0f "\n            print(f"{status} {component:12s}: {latency:6.2f}ms (budget: {budget}ms)")\n\n        print(f"{\'\u2705\' if total_time < self.budget[\'total\'] else \'\u26a0\ufe0f \'} Total:        {total_time:6.2f}ms (budget: {self.budget[\'total\']}ms)")\n\n        # Alert if exceeding budget\n        if total_time > self.budget[\'total\']:\n            self.get_logger().warn(f"LATENCY EXCEEDED: {total_time:.1f}ms > {self.budget[\'total\']}ms")\n            self.activate_fallback()\n\n    def activate_fallback(self):\n        """Fallback if latency budget exceeded."""\n        self.get_logger().error("Activating fallback mode: slower control")\n        # Reduce update rate, use cached detections, etc.\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-3-safety-mechanisms",children:"Part 3: Safety Mechanisms"}),"\n",(0,r.jsx)(n.h3,{id:"watchdog-timer",children:"Watchdog Timer"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# File: safety_monitor.py\n"""\nWatchdog and safety monitoring for autonomous robot.\n"""\n\nimport threading\nimport time\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Bool\n\nclass SafetyMonitor(Node):\n    """Monitor robot health and implement failsafes."""\n\n    def __init__(self):\n        super().__init__(\'safety_monitor\')\n\n        self.watchdog_timeout = 0.5  # 500 ms heartbeat required\n        self.last_heartbeat = time.time()\n        self.is_healthy = True\n\n        # Subscribe to heartbeat from control node\n        self.heartbeat_sub = self.create_subscription(\n            Bool, \'/heartbeat\', self.heartbeat_callback, 10)\n\n        # Publish emergency stop status\n        self.estop_pub = self.create_publisher(Bool, \'/emergency_stop\', 10)\n\n        # Watchdog timer (check health every 100 ms)\n        self.timer = self.create_timer(0.1, self.check_health)\n\n    def heartbeat_callback(self, msg: Bool):\n        """Received heartbeat from control node."""\n        self.last_heartbeat = time.time()\n        self.is_healthy = True\n\n    def check_health(self):\n        """Check if control node is alive."""\n        time_since_heartbeat = time.time() - self.last_heartbeat\n\n        if time_since_heartbeat > self.watchdog_timeout:\n            # Control node is frozen/dead\n            self.is_healthy = False\n            self.get_logger().error(\n                f"WATCHDOG TIMEOUT: No heartbeat for {time_since_heartbeat:.2f}s")\n            self.emergency_stop()\n        else:\n            self.is_healthy = True\n\n    def emergency_stop(self):\n        """Execute emergency stop."""\n        self.get_logger().critical("EMERGENCY STOP ACTIVATED")\n\n        # Publish stop command\n        stop_msg = Bool()\n        stop_msg.data = True  # True = emergency stop active\n        self.estop_pub.publish(stop_msg)\n\n        # In real system:\n        # - Cut power to motors\n        # - Engage brakes\n        # - Alert operator\n        # - Log failure\n\ndef main(args=None):\n    rclpy.init(args=args)\n    monitor = SafetyMonitor()\n    rclpy.spin(monitor)\n    monitor.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"emergency-stop-implementation",children:"Emergency Stop Implementation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# File: emergency_stop_node.py\n"""\nHardware-level emergency stop handler.\n"""\n\nimport RPi.GPIO as GPIO\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Bool\n\nclass EmergencyStopNode(Node):\n    """Hardware emergency stop."""\n\n    def __init__(self):\n        super().__init__(\'emergency_stop_hardware\')\n\n        # GPIO pin for motor enable\n        self.MOTOR_ENABLE_PIN = 17\n        GPIO.setmode(GPIO.BCM)\n        GPIO.setup(self.MOTOR_ENABLE_PIN, GPIO.OUT)\n        GPIO.output(self.MOTOR_ENABLE_PIN, GPIO.HIGH)  # Enabled by default\n\n        # Subscribe to emergency stop topic\n        self.estop_sub = self.create_subscription(\n            Bool, \'/emergency_stop\', self.estop_callback, 10)\n\n        self.get_logger().info("Emergency stop handler ready")\n\n    def estop_callback(self, msg: Bool):\n        """Received emergency stop command."""\n        if msg.data:  # True = activate stop\n            self.get_logger().critical("\ud83d\udea8 EMERGENCY STOP \ud83d\udea8")\n            GPIO.output(self.MOTOR_ENABLE_PIN, GPIO.LOW)  # Disable motors\n        else:  # False = resume\n            self.get_logger().info("Emergency stop cleared - motors re-enabled")\n            GPIO.output(self.MOTOR_ENABLE_PIN, GPIO.HIGH)  # Enable motors\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = EmergencyStopNode()\n    try:\n        rclpy.spin(node)\n    finally:\n        GPIO.cleanup()\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-4-deployment-on-physical-jetson",children:"Part 4: Deployment on Physical Jetson"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-prepare-jetson",children:"Step 1: Prepare Jetson"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# SSH into Jetson\nssh nvidia@jetson-orin-nano.local\n\n# Update system\nsudo apt update && sudo apt upgrade -y\n\n# Install ROS 2 Humble\nsudo apt install ros-humble-ros-core -y\n\n# Install Python dependencies\npip install torch tensorrt torch2trt numpy opencv-python\n\n# Clone your robot package\ngit clone https://github.com/your-repo/humanoid-ai.git\ncd humanoid-ai\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-2-deploy-models",children:"Step 2: Deploy Models"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Copy optimized TensorRT model\nscp model_jetson_optimized.pt nvidia@jetson:/home/nvidia/humanoid-ai/models/\n\n# Verify model loads\npython3 << \'EOF\'\nimport torch\nmodel = torch.jit.load("models/model_jetson_optimized.pt")\nprint(f"\u2705 Model loaded: {model}")\nEOF\n'})}),"\n",(0,r.jsx)(n.h3,{id:"step-3-run-on-real-hardware",children:"Step 3: Run on Real Hardware"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Start ROS 2\nsource /opt/ros/humble/setup.bash\n\n# Launch robot system\nros2 launch humanoid_ai sim_to_real.launch.py\n\n# In another terminal, verify topics\nros2 topic list\n# Should show: /camera/image_raw, /detections, /cmd_vel, /emergency_stop, etc.\n\n# Monitor latency\nros2 run humanoid_ai latency_monitor.py\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-5-hands-on-labs",children:"Part 5: Hands-On Labs"}),"\n",(0,r.jsx)(n.h3,{id:"lab-1-model-optimization-1-hour",children:"Lab 1: Model Optimization (1 hour)"}),"\n",(0,r.jsx)(n.p,{children:"Convert Chapter 4 trained model to TensorRT. Benchmark on GPU."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance"}),": FP16 model shows 3-5x latency reduction"]}),"\n",(0,r.jsx)(n.h3,{id:"lab-2-real-time-control-loop-1-hour",children:"Lab 2: Real-Time Control Loop (1 hour)"}),"\n",(0,r.jsx)(n.p,{children:"Implement latency budgeting control loop. Verify all components within budget."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance"}),": All loop components ",(0,r.jsx)(n.code,{children:"<33ms"})," total (30 FPS target)"]}),"\n",(0,r.jsx)(n.h3,{id:"lab-3-safety-mechanisms-1-hour",children:"Lab 3: Safety Mechanisms (1 hour)"}),"\n",(0,r.jsx)(n.p,{children:"Implement watchdog + emergency stop. Test by killing control node."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance"}),": Watchdog detects failure, emergency stop activates within 100ms"]}),"\n",(0,r.jsx)(n.h3,{id:"lab-4-jetson-deployment-1-hour",children:"Lab 4: Jetson Deployment (1 hour)"}),"\n",(0,r.jsx)(n.p,{children:"Deploy to physical Jetson Orin Nano. Run end-to-end pipeline."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance"}),": Model runs at >10 FPS with safety monitoring"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-6-troubleshooting-guide",children:"Part 6: Troubleshooting Guide"}),"\n",(0,r.jsx)(n.h3,{id:"issue-model-runs-slow-on-jetson",children:"Issue: Model runs slow on Jetson"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Verify TensorRT optimization: ",(0,r.jsx)(n.code,{children:"model_jetson_optimized.pt"})," size ~50 MB?"]}),"\n",(0,r.jsx)(n.li,{children:"Check input shape: Is inference expecting (1,3,640,480)?"}),"\n",(0,r.jsxs)(n.li,{children:["Profile with ",(0,r.jsx)(n.code,{children:"latency_profiler.py"})," - which component is slow?"]}),"\n",(0,r.jsx)(n.li,{children:"Consider INT8 quantization for 8x speedup"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"issue-latency-spikes-every-few-seconds",children:"Issue: Latency spikes every few seconds"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Check garbage collection: ",(0,r.jsx)(n.code,{children:"gc.disable()"})," in hot loop"]}),"\n",(0,r.jsxs)(n.li,{children:["Verify CPU is not thermal-throttling: Monitor ",(0,r.jsx)(n.code,{children:"/sys/class/thermal/"})]}),"\n",(0,r.jsx)(n.li,{children:"Look for ROS 2 buffer copies: Use zero-copy transports"}),"\n",(0,r.jsx)(n.li,{children:"Reduce image resolution: 640\xd7480 \u2192 320\xd7240"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"issue-control-loop-misses-deadline-occasionally",children:"Issue: Control loop misses deadline occasionally"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Increase thread priority: ",(0,r.jsx)(n.code,{children:"taskset -c 1-4 ros2 run ..."})," (pin to CPU cores)"]}),"\n",(0,r.jsx)(n.li,{children:"Reduce perception quality: Lower inference confidence threshold"}),"\n",(0,r.jsx)(n.li,{children:"Implement fallback: Use cached predictions if deadline missed"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-7-end-of-chapter-exercises",children:"Part 7: End-of-Chapter Exercises"}),"\n",(0,r.jsx)(n.h3,{id:"exercise-1-optimize-your-model-1-hour",children:"Exercise 1: Optimize Your Model (1 hour)"}),"\n",(0,r.jsx)(n.p,{children:"Convert your Chapter 4 model to TensorRT INT8. Measure speedup and accuracy loss."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance"}),": 5-10x speedup, ",(0,r.jsx)(n.code,{children:"<5%"})," accuracy loss"]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-2-deploy-end-to-end-15-hours",children:"Exercise 2: Deploy End-to-End (1.5 hours)"}),"\n",(0,r.jsx)(n.p,{children:"Run complete pipeline on Jetson: perception \u2192 control \u2192 motor commands."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance"}),": Robot responds to detected objects in real time (>10 FPS)"]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-3-safety-testing-1-hour",children:"Exercise 3: Safety Testing (1 hour)"}),"\n",(0,r.jsx)(n.p,{children:"Test watchdog by killing control node. Verify emergency stop triggers."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance"}),": System reaches emergency stop state within 100ms"]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-4-performance-documentation-1-hour",children:"Exercise 4: Performance Documentation (1 hour)"}),"\n",(0,r.jsx)(n.p,{children:"Write deployment guide: model optimization \u2192 Jetson setup \u2192 safety procedures."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance"}),": 2-3 page document with latency metrics, procedures, troubleshooting"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-8-capstone-integration",children:"Part 8: Capstone Integration"}),"\n",(0,r.jsx)(n.p,{children:"Your Humanoid AI Assistant capstone is complete:"}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Chapter 1"}),": Isaac ecosystem foundation\n\u2705 ",(0,r.jsx)(n.strong,{children:"Chapter 2"}),": Digital twin with sensors\n\u2705 ",(0,r.jsx)(n.strong,{children:"Chapter 3"}),": Real-time perception (object detection, SLAM, fusion)\n\u2705 ",(0,r.jsx)(n.strong,{children:"Chapter 4"}),": Synthetic data generation for training\n\u2705 ",(0,r.jsx)(n.strong,{children:"Chapter 5"}),": Production deployment with safety \u2190 FINAL CHAPTER"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Capstone Project Completion Checklist"}),":"]}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Humanoid digital twin running in Isaac Sim"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Object detection model trained on 10K+ synthetic images"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Real-time perception pipeline (>10 FPS)"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Safety monitoring (watchdog, emergency stop)"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Deployed to Jetson or cloud GPU"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Demo video (4-5 min) showing perception + control"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Documentation: architecture, deployment, latency metrics"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Congratulations!"})," You've completed Module 3."]}),"\n",(0,r.jsx)(n.h3,{id:"optional-chapter-6-advanced-topics",children:"Optional: Chapter 6 (Advanced Topics)"}),"\n",(0,r.jsx)(n.p,{children:"If interested in deeper dives:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reinforcement Learning"}),": Train policies in Isaac Lab"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-Robot Coordination"}),": Swarm robotics"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Physics-Informed Networks"}),": Hybrid learning"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Digital Twin Maintenance"}),": Calibration, update"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"continue-to-module-4",children:"Continue to Module 4"}),"\n",(0,r.jsxs)(n.p,{children:["Next module covers ",(0,r.jsx)(n.strong,{children:"Vision-Language-Action Robotics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Large language models (GPT) for task planning"}),"\n",(0,r.jsx)(n.li,{children:"Whisper for speech understanding"}),"\n",(0,r.jsx)(n.li,{children:"End-to-end learned policies"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Chapter Summary"}),": 4-5 hours | Difficulty: Intermediate | Week 10"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.nvidia.com/jetson/jetson-agx-orin-developer-kit/index.html",children:"Jetson Developer Guide"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.nvidia.com/deeplearning/tensorrt/best-practices/",children:"TensorRT Best Practices"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.ros.org/en/foxy/Concepts/About-Real-Time.html",children:"ROS 2 Real-Time"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://www.iso.org/standard/74272.html",children:"Safety in Robotics"})}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"End of Module 3"}),". Great work! \ud83e\udd16"]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>l});var o=t(6540);const r={},i=o.createContext(r);function s(e){const n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);