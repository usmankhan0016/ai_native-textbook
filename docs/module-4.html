<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-4/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Module 4: Vision–Language–Action (VLA) Robotics | Physical AI &amp; Humanoid Robotics Textbook</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://usmankhan0016.github.io/ai_native-textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://usmankhan0016.github.io/ai_native-textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://usmankhan0016.github.io/ai_native-textbook/docs/module-4"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Module 4: Vision–Language–Action (VLA) Robotics | Physical AI &amp; Humanoid Robotics Textbook"><meta data-rh="true" name="description" content="Capstone Module | Duration Modules 1-3"><meta data-rh="true" property="og:description" content="Capstone Module | Duration Modules 1-3"><link data-rh="true" rel="icon" href="/ai_native-textbook/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://usmankhan0016.github.io/ai_native-textbook/docs/module-4"><link data-rh="true" rel="alternate" href="https://usmankhan0016.github.io/ai_native-textbook/docs/module-4" hreflang="en"><link data-rh="true" rel="alternate" href="https://usmankhan0016.github.io/ai_native-textbook/docs/module-4" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Module 4: Vision–Language–Action (VLA) Robotics","item":"https://usmankhan0016.github.io/ai_native-textbook/docs/module-4/"}]}</script><link rel="stylesheet" href="/ai_native-textbook/assets/css/styles.c31051db.css">
<script src="/ai_native-textbook/assets/js/runtime~main.3d4c2b23.js" defer="defer"></script>
<script src="/ai_native-textbook/assets/js/main.a5e2bbf8.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_native-textbook/"><div class="navbar__logo"><img src="/ai_native-textbook/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_native-textbook/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI Textbook</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai_native-textbook/docs/intro">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/usmankhan0016" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_native-textbook/docs/intro"><span title="Welcome to Physical AI &amp; Humanoid Robotics" class="linkLabel_WmDU">Welcome to Physical AI &amp; Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_native-textbook/docs/module-1"><span title="Module 1: ROS 2" class="categoryLinkLabel_W154">Module 1: ROS 2</span></a><button aria-label="Collapse sidebar category &#x27;Module 1: ROS 2&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-1/chapter-1-introduction-to-ros2"><span title="Ch1: Introduction" class="linkLabel_WmDU">Ch1: Introduction</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-1/chapter-2-ros2-architecture"><span title="Ch2: Architecture" class="linkLabel_WmDU">Ch2: Architecture</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-1/chapter-3-ros2-packages-launch"><span title="Chapter 3: Packages, Launch Files, and Parameters" class="linkLabel_WmDU">Chapter 3: Packages, Launch Files, and Parameters</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-1/chapter-4-urdf-for-humanoids"><span title="Chapter 4: URDF for Humanoid Robots" class="linkLabel_WmDU">Chapter 4: URDF for Humanoid Robots</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-1/week-3"><span title="Week 3 Practice Guide" class="linkLabel_WmDU">Week 3 Practice Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-1/week-4"><span title="Week 4 Practice Guide" class="linkLabel_WmDU">Week 4 Practice Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-1/week-5"><span title="Week 5 Practice Guide" class="linkLabel_WmDU">Week 5 Practice Guide</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_native-textbook/docs/module-2"><span title="Module 2: Digital Twin" class="categoryLinkLabel_W154">Module 2: Digital Twin</span></a><button aria-label="Collapse sidebar category &#x27;Module 2: Digital Twin&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-2/chapter-1-digital-twin-introduction"><span title="Ch.1: Digital Twin Introduction" class="linkLabel_WmDU">Ch.1: Digital Twin Introduction</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-2/chapter-2-gazebo-physics-simulation"><span title="Ch.2: Gazebo Physics" class="linkLabel_WmDU">Ch.2: Gazebo Physics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-2/chapter-3-sensor-simulation"><span title="Ch.3: Sensor Simulation" class="linkLabel_WmDU">Ch.3: Sensor Simulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-2/chapter-4-unity-high-fidelity-simulation"><span title="Ch.4: Unity High-Fidelity" class="linkLabel_WmDU">Ch.4: Unity High-Fidelity</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-2/week-6"><span title="Week 6: Gazebo Fundamentals" class="linkLabel_WmDU">Week 6: Gazebo Fundamentals</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-2/week-7"><span title="Week 7: Sensors &amp; Unity" class="linkLabel_WmDU">Week 7: Sensors &amp; Unity</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_native-textbook/docs/module-3"><span title="Module 3: The AI-Robot Brain" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain</span></a><button aria-label="Collapse sidebar category &#x27;Module 3: The AI-Robot Brain&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-3/chapter-1-isaac-introduction"><span title="Ch. 1: Isaac Platform Intro" class="linkLabel_WmDU">Ch. 1: Isaac Platform Intro</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-3/chapter-2-isaac-sim"><span title="Ch. 2: Isaac Sim Robotics" class="linkLabel_WmDU">Ch. 2: Isaac Sim Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-3/chapter-3-isaac-ros"><span title="Ch. 3: Isaac ROS Perception" class="linkLabel_WmDU">Ch. 3: Isaac ROS Perception</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-3/chapter-4-isaac-lab"><span title="Ch. 4: Synthetic Data Isaac Lab" class="linkLabel_WmDU">Ch. 4: Synthetic Data Isaac Lab</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-3/chapter-5-deployment"><span title="Ch. 5: Jetson Deployment" class="linkLabel_WmDU">Ch. 5: Jetson Deployment</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-3/week-8"><span title="Week 8: Isaac Foundations" class="linkLabel_WmDU">Week 8: Isaac Foundations</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-3/week-9-10"><span title="Week 9-10: AI &amp; Capstone" class="linkLabel_WmDU">Week 9-10: AI &amp; Capstone</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" aria-current="page" href="/ai_native-textbook/docs/module-4"><span title="Module 4: Vision–Language–Action (VLA) Robotics" class="categoryLinkLabel_W154">Module 4: Vision–Language–Action (VLA) Robotics</span></a><button aria-label="Collapse sidebar category &#x27;Module 4: Vision–Language–Action (VLA) Robotics&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-4/chapter-1-vla-intro"><span title="Chapter 1: Introduction to Vision–Language–Action Robotics" class="linkLabel_WmDU">Chapter 1: Introduction to Vision–Language–Action Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-4/chapter-2-vision-for-vla"><span title="Chapter 2: Vision for VLA – Building Perception Pipelines" class="linkLabel_WmDU">Chapter 2: Vision for VLA – Building Perception Pipelines</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-4/chapter-3-language-planning-whisper-llm"><span title="Chapter 3: Language Planning with Whisper &amp; Large Language Models" class="linkLabel_WmDU">Chapter 3: Language Planning with Whisper &amp; Large Language Models</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-4/chapter-4-vla-control-architecture"><span title="Chapter 4: VLA Control Architecture &amp; Deployment" class="linkLabel_WmDU">Chapter 4: VLA Control Architecture &amp; Deployment</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_native-textbook/docs/module-4/week-13"><span title="Week 13: VLA Capstone Sprint &amp; Integration" class="linkLabel_WmDU">Week 13: VLA Capstone Sprint &amp; Integration</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_native-textbook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Module 4: Vision–Language–Action (VLA) Robotics</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Module 4: Vision–Language–Action (VLA) Robotics</h1></header>
<p><strong>Capstone Module</strong> | <strong>Duration</strong>: 4 weeks (Weeks 10-13) | <strong>Prerequisite</strong>: Modules 1-3</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-overview">Module Overview<a href="#module-overview" class="hash-link" aria-label="Direct link to Module Overview" title="Direct link to Module Overview" translate="no">​</a></h2>
<p>Module 4 is the <strong>capstone</strong> of the Physical AI &amp; Humanoid Robotics Textbook. You&#x27;ll build a complete Vision-Language-Action (VLA) system—integrating perception, language understanding, and robot control—to create a humanoid that responds to natural language voice commands and executes complex household tasks.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-youll-build">What You&#x27;ll Build<a href="#what-youll-build" class="hash-link" aria-label="Direct link to What You&#x27;ll Build" title="Direct link to What You&#x27;ll Build" translate="no">​</a></h3>
<p>By the end of Module 4, your robot will:</p>
<ol>
<li class=""><strong>Perceive</strong> its environment using RGB + depth sensors (Chapter 2)</li>
<li class=""><strong>Understand</strong> voice commands via speech-to-text (Chapter 3)</li>
<li class=""><strong>Reason</strong> about tasks using Large Language Models (Chapter 3)</li>
<li class=""><strong>Plan</strong> multi-step action sequences (Chapter 3)</li>
<li class=""><strong>Execute</strong> navigation and manipulation in real-time (Chapter 4)</li>
<li class=""><strong>Recover</strong> from failures with automatic replanning (Chapter 4)</li>
<li class=""><strong>Operate safely</strong> with watchdogs and emergency stops (Chapter 4)</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-outcomes">Learning Outcomes<a href="#learning-outcomes" class="hash-link" aria-label="Direct link to Learning Outcomes" title="Direct link to Learning Outcomes" translate="no">​</a></h3>
<p>After completing Module 4, you will be able to:</p>
<ul>
<li class=""><strong>Design and implement</strong> complete VLA architectures for autonomous humanoids</li>
<li class=""><strong>Integrate perception, language, and control</strong> into cohesive systems</li>
<li class=""><strong>Deploy optimized systems</strong> to resource-constrained platforms (Jetson hardware)</li>
<li class=""><strong>Explain the role</strong> of vision, language, and action in embodied AI</li>
<li class=""><strong>Evaluate VLA systems</strong> against technical rubrics (perception accuracy, planning quality, control robustness, safety)</li>
<li class=""><strong>Build and deploy</strong> real-world autonomous robots that understand natural language</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-chapters">Module Chapters<a href="#module-chapters" class="hash-link" aria-label="Direct link to Module Chapters" title="Direct link to Module Chapters" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="chapter-1-introduction-to-vision-language-action-robotics"><strong>Chapter 1: Introduction to Vision-Language-Action Robotics</strong><a href="#chapter-1-introduction-to-vision-language-action-robotics" class="hash-link" aria-label="Direct link to chapter-1-introduction-to-vision-language-action-robotics" title="Direct link to chapter-1-introduction-to-vision-language-action-robotics" translate="no">​</a></h3>
<p><em>Difficulty: Beginner | Time: 8-10 hours</em></p>
<p><strong>Goal</strong>: Understand the VLA paradigm and why it enables autonomous humanoids.</p>
<p><strong>Topics</strong>:</p>
<ul>
<li class="">What is VLA? (Three pillars: Vision, Language, Action)</li>
<li class="">Cognitive robotics vs. classical robotics</li>
<li class="">Real-world VLA systems (OpenAI RT-2, DeepMind RT-X, NVIDIA VLMs)</li>
<li class="">Task representation: skills, behaviors, action graphs</li>
<li class="">Behavior trees for hierarchical task control</li>
</ul>
<p><strong>Key Deliverables</strong>:</p>
<ul>
<li class="">Lab 1: Analyze a real VLA system (OpenAI Robotics or RT-X)</li>
<li class="">Lab 2: Design a VLA architecture for household cleanup</li>
<li class="">Lab 3: Evaluate VLA design trade-offs</li>
<li class="">3 progressive exercises</li>
</ul>
<p><strong>Capstone Connection</strong>: Establishes the architectural framework for your capstone system.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="chapter-2-vision-for-vla--building-perception-pipelines"><strong>Chapter 2: Vision for VLA – Building Perception Pipelines</strong><a href="#chapter-2-vision-for-vla--building-perception-pipelines" class="hash-link" aria-label="Direct link to chapter-2-vision-for-vla--building-perception-pipelines" title="Direct link to chapter-2-vision-for-vla--building-perception-pipelines" translate="no">​</a></h3>
<p><em>Difficulty: Intermediate | Time: 8-10 hours</em></p>
<p><strong>Goal</strong>: Build real-time perception systems that understand scenes for robot reasoning.</p>
<p><strong>Topics</strong>:</p>
<ul>
<li class="">Object detection (YOLO, Mask R-CNN, SAM)</li>
<li class="">Grounding vision-language models (Grounding DINO)</li>
<li class="">Affordance detection (what objects can the robot interact with?)</li>
<li class="">RGB-D fusion (combining color and depth)</li>
<li class="">Multi-view camera fusion</li>
<li class="">Scene graphs (structured scene representations for LLMs)</li>
</ul>
<p><strong>Key Deliverables</strong>:</p>
<ul>
<li class="">Lab 1: Detect objects in scenes with YOLO (90%+ accuracy)</li>
<li class="">Lab 2: Identify pickable/graspable objects with affordance classifier</li>
<li class="">Lab 3: Convert scenes to LLM-readable natural language descriptions</li>
<li class="">ROS 2 perception node code examples</li>
</ul>
<p><strong>Capstone Connection</strong>: Perception node provides scene understanding for LLM planning.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="chapter-3-language-planning-with-whisper--large-language-models"><strong>Chapter 3: Language Planning with Whisper &amp; Large Language Models</strong><a href="#chapter-3-language-planning-with-whisper--large-language-models" class="hash-link" aria-label="Direct link to chapter-3-language-planning-with-whisper--large-language-models" title="Direct link to chapter-3-language-planning-with-whisper--large-language-models" translate="no">​</a></h3>
<p><em>Difficulty: Intermediate | Time: 8-10 hours</em></p>
<p><strong>Goal</strong>: Use language models to decompose voice commands into executable robot skills.</p>
<p><strong>Topics</strong>:</p>
<ul>
<li class="">Whisper speech-to-text API (voice input with &gt;95% accuracy)</li>
<li class="">Prompt engineering for robotics (crafting LLM inputs)</li>
<li class="">Chain-of-thought reasoning (LLM step-by-step task breakdown)</li>
<li class="">Task decomposition (natural language → skill sequences)</li>
<li class="">Mock and real LLM integration</li>
<li class="">Behavior trees for task planning</li>
<li class="">Replanning and failure recovery</li>
</ul>
<p><strong>Key Deliverables</strong>:</p>
<ul>
<li class="">Lab 1: Test Whisper speech recognition on household commands</li>
<li class="">Lab 2: Decompose tasks using mock LLM (core labs)</li>
<li class="">Lab 3: Implement replanning logic for failure recovery</li>
<li class="">Lab 4: Real LLM integration with OpenAI/Claude APIs (bonus)</li>
<li class="">Code examples for Whisper node, LLM decomposer, replanning engine</li>
</ul>
<p><strong>Capstone Connection</strong>: Planning module converts voice → task plans for execution.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="chapter-4-vla-control-architecture--deployment"><strong>Chapter 4: VLA Control Architecture &amp; Deployment</strong><a href="#chapter-4-vla-control-architecture--deployment" class="hash-link" aria-label="Direct link to chapter-4-vla-control-architecture--deployment" title="Direct link to chapter-4-vla-control-architecture--deployment" translate="no">​</a></h3>
<p><em>Difficulty: Advanced | Time: 8-10 hours</em></p>
<p><strong>Goal</strong>: Integrate perception and planning into a unified control system.</p>
<p><strong>Topics</strong>:</p>
<ul>
<li class="">ROS 2 action servers (asynchronous goal-oriented communication)</li>
<li class="">Nav2 navigation stack (autonomous mobile manipulation)</li>
<li class="">MoveIt manipulation (arm motion planning with collision avoidance)</li>
<li class="">VLA orchestrator (central controller coordinating all components)</li>
<li class="">Safety mechanisms (watchdogs, emergency stops)</li>
<li class="">Failure recovery (replanning on task failures)</li>
<li class="">Deployment optimization (model quantization, Jetson platforms)</li>
</ul>
<p><strong>Key Deliverables</strong>:</p>
<ul>
<li class="">Lab 1: Build perception-aware navigation</li>
<li class="">Lab 2: Integrate LLM planning with ROS 2 control</li>
<li class="">Lab 3: Implement safety watchdogs and emergency stops</li>
<li class="">Lab 4: Design deployment optimization strategy</li>
<li class="">VLA orchestrator code</li>
<li class="">Safety watchdog implementation</li>
</ul>
<p><strong>Capstone Connection</strong>: Control module executes full perception → planning → action pipeline.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="week-13-vla-capstone-sprint--integration"><strong>Week 13: VLA Capstone Sprint &amp; Integration</strong><a href="#week-13-vla-capstone-sprint--integration" class="hash-link" aria-label="Direct link to week-13-vla-capstone-sprint--integration" title="Direct link to week-13-vla-capstone-sprint--integration" translate="no">​</a></h3>
<p><em>Difficulty: Advanced | Time: 40-50 hours (2-week sprint)</em></p>
<p><strong>Goal</strong>: Build and evaluate a complete end-to-end VLA system.</p>
<p><strong>Capstone Project</strong>: &quot;Embodied AI Household Assistant&quot;</p>
<p><strong>What You&#x27;ll Build</strong>:</p>
<ul>
<li class="">Complete VLA pipeline in simulation (Isaac Lab)</li>
<li class="">Voice-controlled household task execution</li>
<li class="">Real-time perception, planning, and control</li>
<li class="">Safety-critical systems with watchdogs and recovery</li>
</ul>
<p><strong>Evaluation Rubric</strong> (4 dimensions):</p>
<ol>
<li class=""><strong>Perception</strong> (25%): Object detection accuracy <code>&gt;90%</code>, affordance extraction, <code>&lt;1</code>00ms` latency</li>
<li class=""><strong>LLM Planning</strong> (25%): Multi-step task decomposition, robust fallbacks, semantic understanding</li>
<li class=""><strong>Control &amp; Integration</strong> (35%): Full pipeline execution, <code>&lt;3</code>3ms` control loop, failure recovery</li>
<li class=""><strong>Safety</strong> (15%): Watchdogs, emergency stops, collision avoidance, proven stress tests</li>
</ol>
<p><strong>Bonus Challenge</strong>: Deploy to real Jetson hardware with quantized models and benchmark real-time performance.</p>
<p><strong>Deliverables</strong>:</p>
<ul>
<li class="">Complete ROS 2 system with all components</li>
<li class="">Technical documentation and architecture diagrams</li>
<li class="">Evaluation results with metrics</li>
<li class="">5-minute demo video</li>
<li class="">Capstone report</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-learning-path">Module Learning Path<a href="#module-learning-path" class="hash-link" aria-label="Direct link to Module Learning Path" title="Direct link to Module Learning Path" translate="no">​</a></h2>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Week 10: Chapters 1-2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ Mon-Wed: Chapter 1 (VLA fundamentals)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└─ Wed-Fri: Chapter 2 (Perception pipeline)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Week 11: Chapter 2-3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ Mon-Wed: Chapter 2 (Complete perception)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└─ Wed-Fri: Chapter 3 (Whisper &amp; LLMs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Week 12: Chapters 3-4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ Mon-Wed: Chapter 3 (Complete planning)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└─ Wed-Fri: Chapter 4 (Control architecture)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Week 13: Capstone Sprint (Days 1-10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ Days 1-2: Perception sprint</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ Days 3-4: Planning sprint</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ Days 5-6: Control integration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ Days 7-8: Full pipeline testing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ Day 9: Evaluation &amp; documentation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└─ Days 10+: Refinement, bonus features, hardware (optional)</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="required-knowledge-from-modules-1-3">Required Knowledge (from Modules 1-3)<a href="#required-knowledge-from-modules-1-3" class="hash-link" aria-label="Direct link to Required Knowledge (from Modules 1-3)" title="Direct link to Required Knowledge (from Modules 1-3)" translate="no">​</a></h3>
<ul>
<li class="">ROS 2 fundamentals (publishers, subscribers, services, actions)</li>
<li class="">Digital twin simulation (Gazebo or Isaac Sim)</li>
<li class="">Python 3.10+ programming</li>
<li class="">Basic robotics concepts (kinematics, control, navigation)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="recommended-tools">Recommended Tools<a href="#recommended-tools" class="hash-link" aria-label="Direct link to Recommended Tools" title="Direct link to Recommended Tools" translate="no">​</a></h3>
<ul>
<li class="">ROS 2 Humble (installed and configured)</li>
<li class="">NVIDIA Isaac Lab (for simulation) or Gazebo Garden</li>
<li class="">Python with PyTorch, OpenCV, numpy</li>
<li class="">Git and GitHub (for version control)</li>
<li class="">Docker (for reproducible environments)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="optional-hardware">Optional Hardware<a href="#optional-hardware" class="hash-link" aria-label="Direct link to Optional Hardware" title="Direct link to Optional Hardware" translate="no">​</a></h3>
<ul>
<li class="">Jetson platform (Orin Nano, Orin NX) for hardware deployment</li>
<li class="">Real humanoid robot (e.g., Tesla Bot, Figure 01, Digit)</li>
<li class="">USB microphone for voice input</li>
<li class="">RGB-D camera (Intel RealSense D435)</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-concepts-youll-master">Key Concepts You&#x27;ll Master<a href="#key-concepts-youll-master" class="hash-link" aria-label="Direct link to Key Concepts You&#x27;ll Master" title="Direct link to Key Concepts You&#x27;ll Master" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="vision-language-action-vla">Vision-Language-Action (VLA)<a href="#vision-language-action-vla" class="hash-link" aria-label="Direct link to Vision-Language-Action (VLA)" title="Direct link to Vision-Language-Action (VLA)" translate="no">​</a></h3>
<p>An integrated architecture where robots perceive their environment, reason about goals using language, and execute actions in real-time. VLA enables natural language control of complex autonomous behaviors.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="multimodal-perception">Multimodal Perception<a href="#multimodal-perception" class="hash-link" aria-label="Direct link to Multimodal Perception" title="Direct link to Multimodal Perception" translate="no">​</a></h3>
<p>Combining RGB images, depth maps, and segmentation outputs to build rich scene understanding for robot reasoning.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="llm-driven-planning">LLM-Driven Planning<a href="#llm-driven-planning" class="hash-link" aria-label="Direct link to LLM-Driven Planning" title="Direct link to LLM-Driven Planning" translate="no">​</a></h3>
<p>Using Large Language Models to decompose natural language commands into executable robot skill sequences—enabling robots to generalize to novel tasks.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="behavior-trees">Behavior Trees<a href="#behavior-trees" class="hash-link" aria-label="Direct link to Behavior Trees" title="Direct link to Behavior Trees" translate="no">​</a></h3>
<p>Hierarchical representations of robot behaviors using composable nodes (selectors, sequences, actions)—enabling modular, reusable task control.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="real-time-control-integration">Real-Time Control Integration<a href="#real-time-control-integration" class="hash-link" aria-label="Direct link to Real-Time Control Integration" title="Direct link to Real-Time Control Integration" translate="no">​</a></h3>
<p>Tight synchronization of perception, planning, and control loops with latency budgets (e.g., <code>&lt;3</code>3ms for 30 Hz real-time operation).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="safety-critical-systems">Safety-Critical Systems<a href="#safety-critical-systems" class="hash-link" aria-label="Direct link to Safety-Critical Systems" title="Direct link to Safety-Critical Systems" translate="no">​</a></h3>
<p>Watchdogs, emergency stops, and failure recovery mechanisms that ensure safe operation in human environments.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="technical-stack">Technical Stack<a href="#technical-stack" class="hash-link" aria-label="Direct link to Technical Stack" title="Direct link to Technical Stack" translate="no">​</a></h2>
<table><thead><tr><th>Component</th><th>Technologies</th></tr></thead><tbody><tr><td><strong>Perception</strong></td><td>YOLO, Mask R-CNN, SAM, Grounding DINO</td></tr><tr><td><strong>Speech-to-Text</strong></td><td>OpenAI Whisper API</td></tr><tr><td><strong>Language Models</strong></td><td>GPT-4, Claude, open-source LLMs</td></tr><tr><td><strong>Robot Control</strong></td><td>ROS 2 Humble, Nav2, MoveIt</td></tr><tr><td><strong>Simulation</strong></td><td>NVIDIA Isaac Lab, Gazebo Garden</td></tr><tr><td><strong>Deployment</strong></td><td>Jetson Orin (TensorRT), Docker</td></tr><tr><td><strong>Programming</strong></td><td>Python 3.10+, C++ (optional)</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="success-criteria">Success Criteria<a href="#success-criteria" class="hash-link" aria-label="Direct link to Success Criteria" title="Direct link to Success Criteria" translate="no">​</a></h2>
<p>By completing Module 4, you will have:</p>
<ul>
<li class="">✅ Implemented a complete VLA system (perception + planning + control)</li>
<li class="">✅ Demonstrated end-to-end task execution from voice commands</li>
<li class="">✅ Evaluated your system against a rigorous technical rubric</li>
<li class="">✅ Deployed to simulation with real-time performance (<code>&lt;5</code>0ms control loop)</li>
<li class="">✅ (Bonus) Deployed to physical Jetson hardware</li>
<li class="">✅ Documented your system architecture and evaluation results</li>
<li class="">✅ Presented your capstone project with demo video and report</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="resources">Resources<a href="#resources" class="hash-link" aria-label="Direct link to Resources" title="Direct link to Resources" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="official-documentation">Official Documentation<a href="#official-documentation" class="hash-link" aria-label="Direct link to Official Documentation" title="Direct link to Official Documentation" translate="no">​</a></h3>
<ul>
<li class=""><a href="https://docs.ros.org/en/humble/" target="_blank" rel="noopener noreferrer" class="">ROS 2 Humble Docs</a></li>
<li class=""><a href="https://isaac-sim.github.io/" target="_blank" rel="noopener noreferrer" class="">NVIDIA Isaac Lab Docs</a></li>
<li class=""><a href="https://moveit.readthedocs.io/" target="_blank" rel="noopener noreferrer" class="">MoveIt2 Documentation</a></li>
<li class=""><a href="https://nav2.org/" target="_blank" rel="noopener noreferrer" class="">Nav2 Documentation</a></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-research-papers">Key Research Papers<a href="#key-research-papers" class="hash-link" aria-label="Direct link to Key Research Papers" title="Direct link to Key Research Papers" translate="no">​</a></h3>
<ul>
<li class="">Brohan et al. (2023): &quot;RT-2: Vision-Language-Action Models&quot; - arXiv:2307.15818</li>
<li class="">Padalkar et al. (2024): &quot;RT-X: Robotics Transformer&quot; - DeepMind Blog</li>
<li class="">Kirillov et al. (2023): &quot;Segment Anything&quot; - arXiv:2304.02135</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="community-resources">Community Resources<a href="#community-resources" class="hash-link" aria-label="Direct link to Community Resources" title="Direct link to Community Resources" translate="no">​</a></h3>
<ul>
<li class="">ROS2 Discourse: <a href="https://discourse.ros.org/" target="_blank" rel="noopener noreferrer" class="">https://discourse.ros.org/</a></li>
<li class="">Robotics Stack Exchange: <a href="https://robotics.stackexchange.com/" target="_blank" rel="noopener noreferrer" class="">https://robotics.stackexchange.com/</a></li>
<li class="">GitHub: ROS2, Isaac Lab, MoveIt projects</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="grading--evaluation">Grading &amp; Evaluation<a href="#grading--evaluation" class="hash-link" aria-label="Direct link to Grading &amp; Evaluation" title="Direct link to Grading &amp; Evaluation" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-grading">Module Grading<a href="#module-grading" class="hash-link" aria-label="Direct link to Module Grading" title="Direct link to Module Grading" translate="no">​</a></h3>
<ul>
<li class=""><strong>Chapter Assignments</strong> (40%): Labs, exercises, comprehension</li>
<li class=""><strong>Capstone Project</strong> (60%):<!-- -->
<ul>
<li class="">Perception subsystem (25% of capstone)</li>
<li class="">Planning subsystem (25% of capstone)</li>
<li class="">Control &amp; integration (35% of capstone)</li>
<li class="">Safety mechanisms (15% of capstone)</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="capstone-grading">Capstone Grading<a href="#capstone-grading" class="hash-link" aria-label="Direct link to Capstone Grading" title="Direct link to Capstone Grading" translate="no">​</a></h3>
<ul>
<li class=""><strong>Excellent</strong> (A: 95-100%): All systems functional, advanced features, robust deployment</li>
<li class=""><strong>Good</strong> (B: 85-94%): Core systems work, most features implemented</li>
<li class=""><strong>Fair</strong> (C: 75-84%): Basic functionality, limited features</li>
<li class=""><strong>Below Fair</strong> (D/F: <code>&lt;7</code>5%): Incomplete or non-functional</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="frequently-asked-questions">Frequently Asked Questions<a href="#frequently-asked-questions" class="hash-link" aria-label="Direct link to Frequently Asked Questions" title="Direct link to Frequently Asked Questions" translate="no">​</a></h2>
<p><strong>Q: Do I need real robot hardware?</strong>
A: No! The capstone can be completed entirely in simulation. Hardware is optional (bonus challenge).</p>
<p><strong>Q: What if I&#x27;ve never worked with LLMs before?</strong>
A: Chapter 3 teaches prompting from scratch. No prior ML experience required.</p>
<p><strong>Q: How much time should I spend per week?</strong>
A: Plan 40-50 hours over 4 weeks (~10-12 hours per week). The capstone sprint (Week 13) is intensive.</p>
<p><strong>Q: Can I work in teams?</strong>
A: Yes! Capstone projects can be team efforts (2-3 people). Specify team composition in submission.</p>
<p><strong>Q: What if my perception accuracy isn&#x27;t &gt;90%?</strong>
A: The rubric rewards effort and reasoning. Document your challenges and proposed solutions.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">​</a></h2>
<ol>
<li class=""><strong>Start with Chapter 1</strong> to understand VLA concepts and architectures</li>
<li class=""><strong>Build perception</strong> (Chapter 2) and test on sample scenes</li>
<li class=""><strong>Implement planning</strong> (Chapter 3) with mock LLM first</li>
<li class=""><strong>Integrate control</strong> (Chapter 4) to create the full pipeline</li>
<li class=""><strong>Execute the capstone sprint</strong> (Week 13) to build and evaluate your system</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="contact--support">Contact &amp; Support<a href="#contact--support" class="hash-link" aria-label="Direct link to Contact &amp; Support" title="Direct link to Contact &amp; Support" translate="no">​</a></h2>
<ul>
<li class=""><strong>Instructors</strong>: Available for office hours and Q&amp;A</li>
<li class=""><strong>Course Discord</strong>: Real-time help and peer discussion</li>
<li class=""><strong>Discussion Board</strong>: Async questions and answers</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-4-checklist">Module 4 Checklist<a href="#module-4-checklist" class="hash-link" aria-label="Direct link to Module 4 Checklist" title="Direct link to Module 4 Checklist" translate="no">​</a></h2>
<p>As you complete each chapter, mark these off:</p>
<ul class="contains-task-list containsTaskList_mC6p">
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Chapter 1: VLA Fundamentals (Learn the concepts)</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Chapter 2: Perception (Build object detection + scene understanding)</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Chapter 3: Language Planning (Implement Whisper + LLM decomposition)</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Chapter 4: Control Architecture (Wire everything together)</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Week 13 Capstone: Build, evaluate, and present your VLA system</li>
</ul>
<hr>
<p><strong>Welcome to Module 4: Vision-Language-Action Robotics!</strong></p>
<p><strong>This is where it all comes together.</strong> You&#x27;ll build state-of-the-art autonomous systems that understand natural language and execute complex real-world tasks. Let&#x27;s get started!</p>
<hr>
<p><strong><a class="" href="/ai_native-textbook/docs/module-4/chapter-1-vla-intro">Start with Chapter 1: Introduction to Vision-Language-Action Robotics →</a></strong></p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_native-textbook/docs/module-3/week-9-10"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Week 9-10: AI &amp; Capstone</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_native-textbook/docs/module-4/chapter-1-vla-intro"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 1: Introduction to Vision–Language–Action Robotics</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#module-overview" class="table-of-contents__link toc-highlight">Module Overview</a><ul><li><a href="#what-youll-build" class="table-of-contents__link toc-highlight">What You&#39;ll Build</a></li><li><a href="#learning-outcomes" class="table-of-contents__link toc-highlight">Learning Outcomes</a></li></ul></li><li><a href="#module-chapters" class="table-of-contents__link toc-highlight">Module Chapters</a><ul><li><a href="#chapter-1-introduction-to-vision-language-action-robotics" class="table-of-contents__link toc-highlight"><strong>Chapter 1: Introduction to Vision-Language-Action Robotics</strong></a></li><li><a href="#chapter-2-vision-for-vla--building-perception-pipelines" class="table-of-contents__link toc-highlight"><strong>Chapter 2: Vision for VLA – Building Perception Pipelines</strong></a></li><li><a href="#chapter-3-language-planning-with-whisper--large-language-models" class="table-of-contents__link toc-highlight"><strong>Chapter 3: Language Planning with Whisper &amp; Large Language Models</strong></a></li><li><a href="#chapter-4-vla-control-architecture--deployment" class="table-of-contents__link toc-highlight"><strong>Chapter 4: VLA Control Architecture &amp; Deployment</strong></a></li><li><a href="#week-13-vla-capstone-sprint--integration" class="table-of-contents__link toc-highlight"><strong>Week 13: VLA Capstone Sprint &amp; Integration</strong></a></li></ul></li><li><a href="#module-learning-path" class="table-of-contents__link toc-highlight">Module Learning Path</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a><ul><li><a href="#required-knowledge-from-modules-1-3" class="table-of-contents__link toc-highlight">Required Knowledge (from Modules 1-3)</a></li><li><a href="#recommended-tools" class="table-of-contents__link toc-highlight">Recommended Tools</a></li><li><a href="#optional-hardware" class="table-of-contents__link toc-highlight">Optional Hardware</a></li></ul></li><li><a href="#key-concepts-youll-master" class="table-of-contents__link toc-highlight">Key Concepts You&#39;ll Master</a><ul><li><a href="#vision-language-action-vla" class="table-of-contents__link toc-highlight">Vision-Language-Action (VLA)</a></li><li><a href="#multimodal-perception" class="table-of-contents__link toc-highlight">Multimodal Perception</a></li><li><a href="#llm-driven-planning" class="table-of-contents__link toc-highlight">LLM-Driven Planning</a></li><li><a href="#behavior-trees" class="table-of-contents__link toc-highlight">Behavior Trees</a></li><li><a href="#real-time-control-integration" class="table-of-contents__link toc-highlight">Real-Time Control Integration</a></li><li><a href="#safety-critical-systems" class="table-of-contents__link toc-highlight">Safety-Critical Systems</a></li></ul></li><li><a href="#technical-stack" class="table-of-contents__link toc-highlight">Technical Stack</a></li><li><a href="#success-criteria" class="table-of-contents__link toc-highlight">Success Criteria</a></li><li><a href="#resources" class="table-of-contents__link toc-highlight">Resources</a><ul><li><a href="#official-documentation" class="table-of-contents__link toc-highlight">Official Documentation</a></li><li><a href="#key-research-papers" class="table-of-contents__link toc-highlight">Key Research Papers</a></li><li><a href="#community-resources" class="table-of-contents__link toc-highlight">Community Resources</a></li></ul></li><li><a href="#grading--evaluation" class="table-of-contents__link toc-highlight">Grading &amp; Evaluation</a><ul><li><a href="#module-grading" class="table-of-contents__link toc-highlight">Module Grading</a></li><li><a href="#capstone-grading" class="table-of-contents__link toc-highlight">Capstone Grading</a></li></ul></li><li><a href="#frequently-asked-questions" class="table-of-contents__link toc-highlight">Frequently Asked Questions</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li><li><a href="#contact--support" class="table-of-contents__link toc-highlight">Contact &amp; Support</a></li><li><a href="#module-4-checklist" class="table-of-contents__link toc-highlight">Module 4 Checklist</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Modules</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ai_native-textbook/docs/module-1">Module 1: ROS 2</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://docs.ros.org/en/humble/" target="_blank" rel="noopener noreferrer" class="footer__link-item">ROS 2 Documentation<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://developer.nvidia.com/isaac-sim" target="_blank" rel="noopener noreferrer" class="footer__link-item">NVIDIA Isaac Sim<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/usmankhan0016" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Textbook. Built with dedication and ❤ by Usman Nasir.</div></div></div></footer></div>
</body>
</html>